{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='index'></a>\n",
    "# Deep Q Learning\n",
    "\n",
    "* [Space Invaders](#space-invaders)\n",
    "    * [DQN](#dqn)\n",
    "    * [Memory](#memory)\n",
    "    * [Training](#training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Tuple\n",
    "import warnings\n",
    "from collections import deque\n",
    "\n",
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import transform\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to index](#index)\n",
    "\n",
    "<a id='space-invaders'></a>\n",
    "## Space Invaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: Box(210, 160, 3)\n",
      "No. actions: 6\n"
     ]
    }
   ],
   "source": [
    "# env = retro.make(game='SpaceInvaders-Atari2600')\n",
    "env = gym.make('SpaceInvaders-v0')\n",
    "\n",
    "print('State size: {}\\nNo. actions: {}'.format(env.observation_space, env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(frame, resize=(110, 84)):\n",
    "    '''\n",
    "        Converts the frame from RGB to \n",
    "        grayscale, crops it, normalises \n",
    "        the values to 0-1 range, and re-\n",
    "        sizes to 110 x 84.\n",
    "    '''\n",
    "    gray = rgb2gray(frame)\n",
    "    cropped = gray[8:-12, 4:-12]\n",
    "    normalised = cropped / 255.0\n",
    "    return transform.resize(normalised, resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_frames(stack, frame, resize=(110, 84)):\n",
    "    '''\n",
    "        Adds a frame to the stack\n",
    "        and returns a 3D np.array \n",
    "        of stacked frames, i.e.\n",
    "        110 x 84 x 3\n",
    "    '''\n",
    "    stack.append(preprocess(frame, resize))\n",
    "    return np.stack(stack, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_frames(frames, dpi: int=72):\n",
    "    fig = plt.figure(figsize=(frames[0].shape[1] // dpi, frames[0].shape[0] // dpi), dpi=dpi)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    return animation.FuncAnimation(fi, animate, frames=len(frames), interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_tensorboard(network, path):\n",
    "    '''\n",
    "        Launch with: tensorboard --logdir=path\n",
    "    '''\n",
    "    writer = tf.summary.FileWriter(path)\n",
    "    tf.summary.scalar('Loss', network.loss)\n",
    "    return tf.summary.merge_all() # tensorboard \"handle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to index](#index)\n",
    "\n",
    "<a id='dqn'></a>\n",
    "### DQN - Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_size: Tuple[int, int, int],\n",
    "        n_actions: int,\n",
    "        alpha: int,\n",
    "        name: str='DQN'\n",
    "    ):\n",
    "        self.reset()\n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            '''\n",
    "                A context manager for defining ops that creates variables (layers).\n",
    "\n",
    "                This context manager validates that the (optional) values are from t\n",
    "                he same graph, ensures that graph is the default graph, and pushes a \n",
    "                name scope and a variable scope.\n",
    "                \n",
    "                See https://www.tensorflow.org/api_docs/python/tf/variable_scope \n",
    "            '''\n",
    "            self.inputs = tf.placeholder(tf.float32, (None, *state_size), name='inputs')\n",
    "            self.actions = tf.placeholder(tf.float32, (None, n_actions), name='actions')\n",
    "            self.Q_target = tf.placeholder(tf.float32, [None], name='Q_target') # R(s, a) + gamma * max(Q_hat(s', a'))\n",
    "            \n",
    "            self.__conv1 = tf.layers.conv2d(\n",
    "                inputs=self.inputs,\n",
    "                activation=tf.nn.elu,\n",
    "                filters=32,\n",
    "                kernel_size=(8, 8),\n",
    "                strides=(4, 4),\n",
    "                padding='VALID',\n",
    "                kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                name='conv1'\n",
    "            )\n",
    "            \n",
    "            self.__conv2 = tf.layers.conv2d(\n",
    "                inputs=self.__conv1,\n",
    "                activation=tf.nn.elu,\n",
    "                filters=64, \n",
    "                kernel_size=(4, 4),\n",
    "                strides=(2, 2),\n",
    "                padding='VALID',\n",
    "                kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                name='conv2'\n",
    "            )\n",
    "            \n",
    "            self.__conv3 = tf.layers.conv2d(\n",
    "                inputs=self.__conv2,\n",
    "                activation=tf.nn.elu,\n",
    "                filters=64, \n",
    "                kernel_size=(3, 3),\n",
    "                strides=(2, 2),\n",
    "                padding='VALID',\n",
    "                kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                name='conv3'\n",
    "            )\n",
    "            \n",
    "            self.__dense1 = tf.layers.dense(\n",
    "                inputs=tf.layers.flatten(self.__conv3, name='flattened'),\n",
    "                activation=tf.nn.elu,\n",
    "                units=512,\n",
    "                kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                name='dense1'\n",
    "            )\n",
    "            \n",
    "            self.__dense2 = tf.layers.dense(\n",
    "                inputs=self.__dense1,\n",
    "                activation=None,\n",
    "                units=n_actions,\n",
    "                kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                name='dense2'\n",
    "            )\n",
    "            \n",
    "            self.output = self.__dense2\n",
    "            self.Q_hat = tf.reduce_sum(tf.multiply(self.output, self.actions))\n",
    "            self.loss = tf.reduce_mean(tf.square(self.Q_target - self.Q_hat))\n",
    "            self.optimiser = tf.train.AdamOptimizer(alpha).minimize(self.loss)\n",
    "            \n",
    "    def reset(self):\n",
    "        tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to index](#index)\n",
    "\n",
    "<a id='memory'></a>\n",
    "### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self, size: int, random_state: int=None):\n",
    "        self.__rng = np.random.RandomState(random_state)\n",
    "        self.__buffer = deque(maxlen=size)\n",
    "        \n",
    "    def add(self, experience: Tuple):\n",
    "        self.__buffer.append(experience)\n",
    "        \n",
    "    def sample(self, batch_size: int):\n",
    "        assert batch_size < len(self.__buffer)\n",
    "        return self.__rng.choice(self.__buffer, batch_size, replace=False).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to index](#index)\n",
    "\n",
    "<a id='training'></a>\n",
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f5ef9cbf25489cb74100a21ea4b993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a7e4d900404dc59278a641d8ea3b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "frame_size = (110, 84) # size of the preprocessed game frame\n",
    "stack_size = 4 # no. frames stacked together\n",
    "batch_size = 64\n",
    "n_pre_training_episodes = 10\n",
    "n_training_episodes = 50\n",
    "n_t_periods = 50000\n",
    "alpha = 0.001 # learning rate\n",
    "epsilon_0 = 1.0 # starting exploration rate\n",
    "epsilon_min = 0.01\n",
    "decay = 1e-4 # exploration decay rate\n",
    "gamma = 0.9 # rewards discount rate\n",
    "memory_size = 100000\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "frame = env.reset() # get Oth state\n",
    "stack = deque([preprocess(frame) for _ in range(stack_size)], maxlen=stack_size) # setup the frame stack\n",
    "state = stack_frames(stack, frame, resize=frame_size)\n",
    "memory = Memory(memory_size, random_state=42)\n",
    "state_size = (*frame_size, stack_size)\n",
    "\n",
    "assert state.shape == state_size\n",
    "\n",
    "# \"Pre-train\" the agent by populating the memory\n",
    "# with experiences (state, action, reward, state_new)\n",
    "# from taking random actions.\n",
    "with tqdm_notebook(total=n_pre_training_episodes) as pbar:\n",
    "    pbar.set_description('Pre-training')\n",
    "    \n",
    "    for episode in range(n_pre_training_episodes):\n",
    "        action = rng.randint(0, env.action_space.n)\n",
    "        frame, reward, game_over, _ = env.step(action)\n",
    "        state_new = stack_frames(stack, frame, resize=frame_size)\n",
    "\n",
    "        if game_over:\n",
    "            state_new = np.zeros(state.shape)\n",
    "            memory.add((state, action, reward, state_new))\n",
    "            frame = env.reset()\n",
    "            state = stack_frames(stack, rame, resize=frame_size)\n",
    "        else:\n",
    "            memory.add((state, action, reward, state_new))\n",
    "            state = state_new            \n",
    "            \n",
    "        pbar.update(1)\n",
    "\n",
    "dqn = DQN(state_size, env.action_space.n, alpha)\n",
    "tensorboard_hanlde = setup_tensorboard(dqn, path='tensorboard/dqn/1')\n",
    "\n",
    "with tqdm_notebook(total=n_training_episodes) as pbar:\n",
    "    pbar.set_description('Training')\n",
    "    \n",
    "    for episode in range(n_training_episodes):\n",
    "        \n",
    "    \n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
